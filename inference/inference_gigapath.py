import os
import json
from collections import defaultdict
from PIL import Image
import torch
from chromadb import PersistentClient

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.6.0"

# âš ï¸ GigaPath ì„ë² ë”©ìœ¼ë¡œ êµ¬ì¶•ëœ ì»¬ë ‰ì…˜ëª…ìœ¼ë¡œ ë°”ê¾¸ì„¸ìš”
collection_name = "tile_embeddings_gigapath"

top_k = 1
vote_mode = "majority"        # "majority" or "weighted"
output_path = "predictions_v0.6.0_gigapath.json"

# =========================
# âœ… ëª¨ë¸, ì „ì²˜ë¦¬ (GigaPath / timm)
# =========================
import timm
from torchvision import transforms

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# GigaPath íƒ€ì¼ ì¸ì½”ë” ë¡œë“œ (HF ë™ì˜ ë° í† í° í•„ìš”í•  ìˆ˜ ìˆìŒ)
model = timm.create_model("hf_hub:prov-gigapath/prov-gigapath", pretrained=True).to(device)
model.eval()

# ê¶Œì¥ ì „ì²˜ë¦¬
transform = transforms.Compose([
    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225)),
])

# =========================
# âœ… ChromaDB ì´ˆê¸°í™”
# =========================
client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)
# âš ï¸ ì»¬ë ‰ì…˜ì˜ metricì€ cosine ê¶Œì¥.
# âš ï¸ ë°˜ë“œì‹œ DBë„ GigaPath ì„ë² ë”©ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ìˆì–´ì•¼ ìœ íš¨í•œ ê²€ìƒ‰ì´ ë©ë‹ˆë‹¤.

# =========================
# âœ… ìœ í‹¸: ì„ë² ë”© ì¶”ì¶œ (GigaPath)
# =========================
@torch.inference_mode()
def image_embedding(pil_img: Image.Image):
    x = transform(pil_img).unsqueeze(0).to(device, non_blocking=True)   # (1, C, H, W)
    feat = model(x)                        # ë³´í†µ (1, 1536)
    if isinstance(feat, (list, tuple)):
        feat = feat[0]
    if feat.dim() > 2:                     # ì•ˆì „ ì¥ì¹˜: ë§Œì•½ spatialì´ ìˆìœ¼ë©´ í‰ê· 
        feat = feat.mean(dim=(2, 3))
    feat = torch.nn.functional.normalize(feat, dim=-1)  # L2 ì •ê·œí™”
    return feat.squeeze(0).cpu().tolist()

# =========================
# âœ… ìŠ¬ë¼ì´ë“œ ì „ì²´ ì²˜ë¦¬
# =========================
results = []
slide_dirs = sorted([
    os.path.join(root_dir, d)
    for d in os.listdir(root_dir)
    if os.path.isdir(os.path.join(root_dir, d))
])

for slide_dir in slide_dirs:
    slide_id = os.path.basename(slide_dir)
    tile_paths = sorted([
        os.path.join(slide_dir, f)
        for f in os.listdir(slide_dir)
        if f.lower().endswith(".jpg")
    ])

    if not tile_paths:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
        continue

    vote_scores = defaultdict(float)

    for path in tile_paths:
        try:
            img = Image.open(path).convert("RGB")
            emb = image_embedding(img)

            q = collection.query(
                query_embeddings=[emb],
                n_results=top_k,
                include=["metadatas", "distances"]
            )

            metas = q.get("metadatas", [[]])[0]
            dists = q.get("distances", [[]])[0]

            for m, d in zip(metas, dists):
                caption = (m or {}).get("caption", "(ì—†ìŒ)")
                if vote_mode == "weighted":
                    w = max(0.0, 1.0 - float(d))  # cosine distance â†’ ìœ ì‚¬ë„ë¡œ ë³€í™˜
                    vote_scores[caption] += w
                else:
                    vote_scores[caption] += 1.0

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

    if not vote_scores:
        print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
        continue

    final_caption = max(vote_scores.items(), key=lambda x: x[1])[0]
    final_score = vote_scores[final_caption]

    print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} (ì ìˆ˜: {final_score:.2f}, mode={vote_mode}, K={top_k})")
    print(f"ğŸ“„ {final_caption}")

    results.append({
        "id": f"{slide_id}.tiff",
        "report": final_caption
    })

# =========================
# âœ… JSON ì €ì¥
# =========================
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
