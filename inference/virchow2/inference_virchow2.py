#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
from collections import defaultdict
from typing import List, Tuple, Dict, Any

import torch
from PIL import Image
from chromadb import PersistentClient

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.8.0"

collection_name = "tile_embeddings_virchow2"
top_k = 3
vote_mode = "majority"  # or "weighted"
output_path = "predictions_v0.8.0.json"

VIRCHOW2_DIR = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/virchow2"
CKPT_ST = os.path.join(VIRCHOW2_DIR, "model.safetensors")
CKPT_PT = os.path.join(VIRCHOW2_DIR, "pytorch_model.bin")

# =========================
# âœ… timm / transforms
# =========================
import timm
from safetensors.torch import load_file
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def _strip_prefix_if_present(state_dict: Dict[str, Any], prefixes: Tuple[str, ...] = ("module.", "model.")) -> Dict[str, Any]:
    out = {}
    for k, v in state_dict.items():
        nk = k
        for p in prefixes:
            if nk.startswith(p):
                nk = nk[len(p):]
        out[nk] = v
    return out


def load_virchow2_vith14() -> torch.nn.Module:
    # 1) ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
    if os.path.exists(CKPT_ST):
        raw_state = load_file(CKPT_ST)
        print(f"â–¶ Loaded safetensors: {CKPT_ST}")
    else:
        raw_state = torch.load(CKPT_PT, map_location="cpu")
        if isinstance(raw_state, dict) and "state_dict" in raw_state:
            raw_state = raw_state["state_dict"]
        print(f"â–¶ Loaded bin: {CKPT_PT}")

    state = _strip_prefix_if_present(raw_state)

    # 2) hidden_dim ì¶”ë¡  (fc2: [embed_dim, hidden_dim])
    fc2_key = None
    for k in ("blocks.0.mlp.fc2.weight", "blocks.0.mlp.fc2.fc.weight", "blocks.0.mlp.fc2_layer.weight"):
        if k in state:
            fc2_key = k
            break
    if fc2_key is None:
        raise RuntimeError("ì²´í¬í¬ì¸íŠ¸ì—ì„œ fc2.weight í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    fc2_w = state[fc2_key]
    embed_dim = int(fc2_w.shape[0])   # 1280
    hidden_dim = int(fc2_w.shape[1])  # 3416 (ckpt)
    # â˜… SwiGLUì¼ ë•ŒëŠ” mlp_ratioë¥¼ 'ë‘ ë°°'ë¡œ ë„£ì–´ì•¼ hidden_dimì´ ë§ìŠµë‹ˆë‹¤.
    mlp_ratio = 2.0 * hidden_dim / float(embed_dim)  # = 5.3375
    print(f"[ckpt] embed_dim={embed_dim}, hidden_dim={hidden_dim}, mlp_ratio_for_SwiGLU={mlp_ratio}")

    # 3) timm ëª¨ë¸ ìƒì„± (SwiGLU + SiLU)
    model = timm.create_model(
        "vit_huge_patch14_224",
        pretrained=False,
        num_classes=0,
        global_pool="",
        img_size=224,
        mlp_ratio=mlp_ratio,                 # â˜… 2ë°°ë¡œ ë„£ëŠ”ë‹¤
        mlp_layer=timm.layers.SwiGLUPacked,  # â˜… SwiGLU
        act_layer=torch.nn.SiLU,             # â˜… SiLU
        init_values=1e-5,
        dynamic_img_size=True,
        # í•„ìš” ì‹œ ckptì— ë§ê²Œ ì•„ë˜ ì˜µì…˜ë„ ì‚¬ìš©
        # reg_tokens=4,
        # no_embed_class=True,
    ).to(device)

    # 4) pos_embed shape ë¶ˆì¼ì¹˜ ì‹œ ì œê±°
    if "pos_embed" in state and hasattr(model, "pos_embed"):
        try:
            if state["pos_embed"].shape != model.pos_embed.shape:
                print("âš ï¸ pos_embed shape ë¶ˆì¼ì¹˜ â†’ ì œê±°")
                del state["pos_embed"]
        except Exception:
            pass

    # 5) ê°€ì¤‘ì¹˜ ë¡œë“œ
    missing, unexpected = model.load_state_dict(state, strict=False)
    print(f"[load_state_dict] missing: {len(missing)}, unexpected: {len(unexpected)}")
    if missing[:10]:    print("  - missing (ì• 10ê°œ):", missing[:10])
    if unexpected[:10]: print("  - unexpected (ì• 10ê°œ):", unexpected[:10])

    model.eval()
    return model


print("ğŸ”§ ëª¨ë¸ ë¡œë”© ì¤‘...")
model = load_virchow2_vith14()

# ì „ì²˜ë¦¬: DB êµ¬ì¶• ë•Œì™€ ë™ì¼í•˜ê²Œ resolve_data_config â†’ create_transform ì‚¬ìš©
cfg = resolve_data_config({}, model=model)
transform = create_transform(**cfg)
print("âœ… ëª¨ë¸/ì „ì²˜ë¦¬ ì¤€ë¹„ ì™„ë£Œ")

# =========================
# âœ… ChromaDB ì´ˆê¸°í™”
# =========================
client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)
# metric='cosine' ê°€ì • (distances â‰ˆ 1 - cos_sim)

# =========================
# âœ… ìœ í‹¸: Virchow2 ì„ë² ë”© ì¶”ì¶œ (DBì™€ ë™ì¼ íŒŒì´í”„ë¼ì¸)
# =========================
@torch.inference_mode()
def image_embedding(pil_img: Image.Image) -> List[float]:
    x = transform(pil_img).unsqueeze(0).to(device)  # (1, 3, 224, 224)
    feats = model.forward_features(x)               # [1, N, D] ë˜ëŠ” [1, D]
    if isinstance(feats, (list, tuple)):
        feats = feats[0]
    if feats.ndim == 3:                             # íŒ¨ì¹˜ í† í° í‰ê· í’€ë§
        feats = feats.mean(dim=1)
    emb = torch.nn.functional.normalize(feats, dim=-1)  # L2 normalize
    return emb.squeeze(0).cpu().tolist()


# =========================
# âœ… ë°ì´í„° ìœ í‹¸
# =========================
def iter_slide_dirs(root: str) -> List[str]:
    return sorted([
        os.path.join(root, d)
        for d in os.listdir(root)
        if os.path.isdir(os.path.join(root, d))
    ])


def iter_tile_paths(slide_dir: str) -> List[str]:
    return sorted([
        os.path.join(slide_dir, f)
        for f in os.listdir(slide_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png"))
    ])


def query_topk(emb: List[float], k: int) -> Tuple[List[Dict[str, Any]], List[float]]:
    q = collection.query(
        query_embeddings=[emb],
        n_results=k,
        include=["metadatas", "distances"],
    )
    metas = q.get("metadatas", [[]])[0] or []
    dists = q.get("distances", [[]])[0] or []
    return metas, dists


def vote_scores_update(vote_scores: defaultdict, metas: List[Dict[str, Any]], dists: List[float], mode: str):
    for m, d in zip(metas, dists):
        caption = (m or {}).get("caption", "(ì—†ìŒ)")
        if mode == "weighted":
            w = max(0.0, 1.0 - float(d))  # cosine distance â†’ sim
            vote_scores[caption] += w
        else:
            vote_scores[caption] += 1.0


# =========================
# âœ… ë©”ì¸
# =========================
def main():
    results = []
    slide_dirs = iter_slide_dirs(root_dir)

    if not slide_dirs:
        print("âš ï¸ ì²˜ë¦¬í•  ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    for slide_dir in slide_dirs:
        slide_id = os.path.basename(slide_dir)
        tile_paths = iter_tile_paths(slide_dir)

        if not tile_paths:
            print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
            continue

        vote_scores = defaultdict(float)

        for path in tile_paths:
            try:
                img = Image.open(path).convert("RGB")
                emb = image_embedding(img)
                metas, dists = query_topk(emb, top_k)
                vote_scores_update(vote_scores, metas, dists, vote_mode)
            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

        if not vote_scores:
            print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
            continue

        final_caption, final_score = max(vote_scores.items(), key=lambda x: x[1])

        print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} (ì ìˆ˜: {final_score:.2f}, mode={vote_mode}, K={top_k})")
        print(f"ğŸ“„ {final_caption}")

        results.append({
            "id": f"{slide_id}.tiff",
            "report": final_caption
        })

    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")


if __name__ == "__main__":
    main()
