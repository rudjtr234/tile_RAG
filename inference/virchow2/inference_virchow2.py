import os
import json
from collections import defaultdict
from PIL import Image
import torch
from chromadb import PersistentClient

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.8.0"

# Virchow2 ì„ë² ë”©ìœ¼ë¡œ êµ¬ì¶•ëœ ì»¬ë ‰ì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.
collection_name = "tile_embeddings_virchow2"

top_k = 1                      # 3 ë˜ëŠ” 5 ë“±ìœ¼ë¡œ ì¡°ì ˆ
vote_mode = "majority"         # "majority" or "weighted"
output_path = "predictions_v0.8.0.json"

# =========================
# âœ… Virchow2 ë¡œë“œ (ë¡œì»¬ ê²½ë¡œ)
# =========================
import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ”’ ë¡œì»¬ ëª¨ë¸ ë””ë ‰í† ë¦¬ (ì´ë¯¸ ì¡´ì¬í•¨)
VIRCHOW2_LOCAL_PATH = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/virchow2"

# ë¡œì»¬ í´ë”ì— config.json + pytorch_model.bin(or model.safetensors)ê°€ ìˆìœ¼ë©´ timmì´ ë°”ë¡œ ë¡œë“œí•©ë‹ˆë‹¤.
model = timm.create_model(VIRCHOW2_LOCAL_PATH, pretrained=True).to(device)
model.eval()

# ê¶Œì¥ ì „ì²˜ë¦¬ êµ¬ì„± ìë™ í•´ì„
cfg = resolve_data_config({}, model=model)
transform = create_transform(**cfg)

# =========================
# âœ… ChromaDB ì´ˆê¸°í™”
# =========================
client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)
# ê¶Œì¥: metric='cosine', ì„ë² ë”© ì°¨ì›ì€ Virchow2 ì„ë² ë”©ê³¼ ë™ì¼í•´ì•¼ í•¨.

# =========================
# âœ… ìœ í‹¸: Virchow2 ì„ë² ë”© ì¶”ì¶œ
# =========================
@torch.inference_mode()
def image_embedding(pil_img: Image.Image):
    x = transform(pil_img).unsqueeze(0).to(device)   # (1, C, H, W)
    # timm í‘œì¤€: forward_features -> backbone ì¶œë ¥
    feats = model.forward_features(x)                # (1, D, ...) ë˜ëŠ” (1, D)
    # pre_logits íŠ¹ì§• ì¶”ì¶œ (ë¶„ë¥˜ê¸° ì• ë²¡í„°)
    feats = model.forward_head(feats, pre_logits=True)  # (1, D)
    feats = torch.nn.functional.normalize(feats, dim=-1)
    return feats.squeeze(0).cpu().tolist()           # list[float]

# =========================
# âœ… ìŠ¬ë¼ì´ë“œ ì „ì²´ ì²˜ë¦¬
# =========================
results = []
slide_dirs = sorted([
    os.path.join(root_dir, d)
    for d in os.listdir(root_dir)
    if os.path.isdir(os.path.join(root_dir, d))
])

for slide_dir in slide_dirs:
    slide_id = os.path.basename(slide_dir)
    tile_paths = sorted([
        os.path.join(slide_dir, f)
        for f in os.listdir(slide_dir)
        if f.lower().endswith(".jpg")
    ])

    if not tile_paths:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
        continue

    # íˆ¬í‘œ ì ìˆ˜ ëˆ„ì (ìŠ¬ë¼ì´ë“œ ë‹¨ìœ„)
    vote_scores = defaultdict(float)

    for path in tile_paths:
        try:
            img = Image.open(path).convert("RGB")
            emb = image_embedding(img)

            q = collection.query(
                query_embeddings=[emb],
                n_results=top_k,
                include=["metadatas", "distances"]
            )

            metas = q.get("metadatas", [[]])[0]
            dists = q.get("distances", [[]])[0]

            # ì´ íƒ€ì¼ì˜ Kê°œ ì´ì›ƒ ëª¨ë‘ ë°˜ì˜
            for m, d in zip(metas, dists):
                caption = (m or {}).get("caption", "(ì—†ìŒ)")
                if vote_mode == "weighted":
                    # cosine distance ê°€ì • â†’ ìœ ì‚¬ë„ ê·¼ì‚¬ (1 - d)
                    w = max(0.0, 1.0 - float(d))
                    vote_scores[caption] += w
                else:
                    vote_scores[caption] += 1.0

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

    if not vote_scores:
        print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
        continue

    # ìµœì¢… ìº¡ì…˜ ì„ íƒ
    final_caption = max(vote_scores.items(), key=lambda x: x[1])[0]
    final_score = vote_scores[final_caption]

    print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} (ì ìˆ˜: {final_score:.2f}, mode={vote_mode}, K={top_k})")
    print(f"ğŸ“„ {final_caption}")

    results.append({
        "id": f"{slide_id}.tiff",
        "report": final_caption
    })

# =========================
# âœ… JSON ì €ì¥
# =========================
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
