import os
import json
from collections import defaultdict
from PIL import Image
import torch
import numpy as np
from chromadb import PersistentClient

import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.4.0"  # UNI2 ì„ë² ë”© DB
collection_name = "tile_embeddings_UNI2"

top_k = 3                    # â† ì´ì›ƒ ê°œìˆ˜ (ë°”ë¡œ ë°˜ì˜)
vote_mode = "majority"       # "majority" ë˜ëŠ” "weighted"
output_path = "predictions_v0.4.2.json"

# weighted ëª¨ë“œ ì„¸ë¶€ ì˜µì…˜
USE_SOFTMAX = True           # softmaxë¡œ ì •ê·œí™”
SOFTMAX_T   = 0.1            # softmax ì˜¨ë„ (ì‘ì„ìˆ˜ë¡ ìƒìœ„ ì´ì›ƒì— ë” ê°€ì¤‘)

# =========================
# âœ… ë””ë°”ì´ìŠ¤
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================
# âœ… UNI2-h ë¡œë“œ (timm)
# =========================
timm_kwargs = {
    "img_size": 224,
    "patch_size": 14,
    "depth": 24,
    "num_heads": 24,
    "init_values": 1e-5,
    "embed_dim": 1536,
    "mlp_ratio": 2.66667*2,
    "num_classes": 0,           # íŠ¹ì§• ë²¡í„° ë°˜í™˜
    "no_embed_class": True,
    "mlp_layer": timm.layers.SwiGLUPacked,
    "act_layer": torch.nn.SiLU,
    "reg_tokens": 8,
    "dynamic_img_size": True,
}

model = timm.create_model(
    "hf-hub:MahmoodLab/UNI2-h",
    pretrained=True,
    **timm_kwargs,
).to(device)
model.eval()

# ê¶Œì¥ ì „ì²˜ë¦¬
data_cfg = resolve_data_config({}, model=model)
transform = create_transform(**data_cfg)

# =========================
# âœ… ChromaDB
# =========================
client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)

# =========================
# âœ… ìœ í‹¸
# =========================
def l2_normalize(x: torch.Tensor, dim: int = -1, eps: float = 1e-12) -> torch.Tensor:
    return x / (x.norm(dim=dim, keepdim=True) + eps)

def softmax(x, T=1.0, axis=-1, eps=1e-12):
    x = np.array(x, dtype=np.float64)
    x = x / max(T, eps)
    x = x - np.max(x)
    e = np.exp(x)
    return e / (np.sum(e) + eps)

# =========================
# âœ… ì „ì²´ ì²˜ë¦¬
# =========================
results = []
slide_dirs = sorted(
    [os.path.join(root_dir, d) for d in os.listdir(root_dir)
     if os.path.isdir(os.path.join(root_dir, d))]
)

use_fp16 = (device.type == "cuda")

for slide_dir in slide_dirs:
    slide_id = os.path.basename(slide_dir)
    tile_paths = sorted([os.path.join(slide_dir, f) for f in os.listdir(slide_dir)
                         if f.lower().endswith(".jpg")])

    if not tile_paths:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
        continue

    # ìŠ¬ë¼ì´ë“œ ë‚´ ìº¡ì…˜ ëˆ„ì  ì¹´ìš´í„° (ë¬¸ìì—´ â†’ ì ìˆ˜)
    caption_scores = defaultdict(float)
    total_votes = 0.0

    for path in tile_paths:
        try:
            img = Image.open(path).convert("RGB")
            img_t = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                if use_fp16:
                    with torch.cuda.amp.autocast(dtype=torch.float16):
                        feats = model(img_t)          # (1, 1536)
                else:
                    feats = model(img_t)

            feats = l2_normalize(feats, dim=-1)        # L2 ì •ê·œí™”
            embedding = feats.squeeze(0).detach().cpu().tolist()

            q = collection.query(
                query_embeddings=[embedding],
                n_results=top_k,
                include=["metadatas", "distances"]
            )

            # ê²€ìƒ‰ ê²°ê³¼ íŒŒì‹±
            if not q["metadatas"] or not q["metadatas"][0]:
                continue

            metas = q["metadatas"][0]                 # ê¸¸ì´ = top_k
            dists = q.get("distances", [[]])[0]       # ê¸¸ì´ = top_k (cosine distance: ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
            # ìœ ì‚¬ë„ë¡œ ë³€í™˜ (cosine similarity = 1 - cosine distance)
            sims  = [1.0 - float(d) for d in dists]

            if vote_mode == "majority":
                # top_k ì´ì›ƒ ê°ê° 1í‘œì”©
                for m in metas:
                    cap = m.get("caption", "(ì—†ìŒ)")
                    caption_scores[cap] += 1.0
                    total_votes += 1.0

            elif vote_mode == "weighted":
                if USE_SOFTMAX:
                    weights = softmax(sims, T=SOFTMAX_T)
                else:
                    # ì„ í˜• ì •ê·œí™”(í•©ì´ 1ì´ ë˜ë„ë¡)
                    s = np.array(sims, dtype=np.float64)
                    s = np.clip(s, 0.0, None)
                    denom = s.sum() if s.sum() > 0 else 1.0
                    weights = s / denom

                for m, w in zip(metas, weights):
                    cap = m.get("caption", "(ì—†ìŒ)")
                    caption_scores[cap] += float(w)
                    total_votes += float(w)

            else:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” vote_mode: {vote_mode}")

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

    if not caption_scores:
        print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
        continue

    # ìµœì¢… ìº¡ì…˜ ì„ íƒ
    final_caption = max(caption_scores.items(), key=lambda x: x[1])[0]
    final_score   = caption_scores[final_caption]

    print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id}  |  mode={vote_mode}, top_k={top_k}")
    print(f"ğŸ“„ {final_caption}")
    print(f"ğŸ§® ëˆ„ì  ì ìˆ˜: {final_score:.4f} (ì´ ê°€ì¤‘ í‘œ ìˆ˜: {total_votes:.4f})")

    results.append({
        "id": f"{slide_id}.tiff",
        "report": final_caption
    })

# =========================
# âœ… JSON ì €ì¥
# =========================
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")
