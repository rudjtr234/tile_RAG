# UNI2 + GigaPath ë™ì‹œ ê²€ìƒ‰ â†’ ê²°í•©(RRF/zsum/softsum) â†’ ìŠ¬ë¼ì´ë“œ ë‹¨ìœ„ íˆ¬í‘œ â†’ JSON ì €ì¥ (íŒŒì„œ ì—†ì´ í•œ ë²ˆì— ì‹¤í–‰)

import os
import json
from collections import defaultdict, Counter
from PIL import Image
import math
import torch
import numpy as np

from chromadb import PersistentClient
from chromadb.config import Settings

import timm
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform
from torchvision import transforms

# =========================
# âœ… ê¸°ë³¸ ì„¤ì • (í•„ìš” ì‹œ ì•„ë˜ ê°’ë§Œ ìˆ˜ì •)
# =========================
ROOT_DIR = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"

# DB ê²½ë¡œ & ì»¬ë ‰ì…˜ëª… (â€» ë„¤ê°€ ì¤€ ì´ë¦„ ê·¸ëŒ€ë¡œ)
UNI2_DB_PATH  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.4.0"
GIGA_DB_PATH  = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.6.0"
UNI2_COL_NAME = "tile_embeddings_UNI2"
GIGA_COL_NAME = "tile_embeddings_gigapath"

# ê²€ìƒ‰/ê²°í•© íŒŒë¼ë¯¸í„°
K_BASE        = 60           # ê° DBì—ì„œ ë¨¼ì € ê°€ì ¸ì˜¬ í›„ë³´ ìˆ˜
FUSION_TOPK   = 10            # ë‘ DB ê²°í•© í›„ ìƒìœ„ ëª‡ ê°œë¥¼ ìŠ¬ë¼ì´ë“œ íˆ¬í‘œì— ë°˜ì˜í• ì§€
METRIC        = "cosine"     # 'cosine' | 'l2' | 'similarity'  (Chroma ë°˜í™˜ ì ìˆ˜ ì„±ê²©)
FUSION_METHOD = "rrf"        # 'rrf' | 'zsum' | 'softsum' (ì´ˆê¸°ì—” rrf ê¶Œì¥)
W_UNI2, W_GIGA = 0.5, 0.5    # zsum/softsumì—ì„œë§Œ ì‚¬ìš©

# ìŠ¬ë¼ì´ë“œ ìˆ˜ì¤€ íˆ¬í‘œ ë°©ì‹
VOTE_MODE     = "weighted"   # 'majority' | 'weighted'

# ì¶œë ¥ íŒŒì¼
OUTPUT_PATH   = "predictions_v.0.9.2.json"

# =========================
# âœ… ìœ í‹¸
# =========================
def z_norm(scores):
    if len(scores) <= 1:
        return [0.0 for _ in scores]
    mu = sum(scores)/len(scores)
    var = sum((s-mu)**2 for s in scores)/(len(scores)-1)
    std = var**0.5 if var > 0 else 1.0
    return [(s - mu)/std for s in scores]

def softmax(xs):
    if not xs:
        return []
    m = max(xs)
    exps = [math.exp(x - m) for x in xs]
    s = sum(exps)
    return [e/s for e in exps]

def to_similarity_from_distance(dist_list, metric: str = "cosine"):
    # ê±°ë¦¬(ì‘ì„ìˆ˜ë¡ ìœ ì‚¬) â†’ ìœ ì‚¬ë„(í´ìˆ˜ë¡ ìœ ì‚¬): -distance
    if metric.lower() in ["cosine", "l2", "distance"]:
        return [-float(d) for d in dist_list]
    return [float(d) for d in dist_list]  # ì´ë¯¸ similarityì¸ ê²½ìš°

def rrf_fuse(ids1, ids2, k=60):
    # ë­í¬ ê¸°ë°˜ ê²°í•© (ìŠ¤ì¼€ì¼ í”„ë¦¬)
    fused = defaultdict(float)
    for rank_list in [ids1, ids2]:
        for r, cid in enumerate(rank_list, start=1):
            fused[cid] += 1.0/(k + r)
    return fused

# =========================
# âœ… ì„ë² ë”©: UNI2 (ë„¤ê°€ ì¤€ ì½”ë“œ ê·¸ëŒ€ë¡œ)
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# UNI2-h ë¡œë“œ
timm_kwargs = {
    "img_size": 224, "patch_size": 14, "depth": 24, "num_heads": 24,
    "init_values": 1e-5, "embed_dim": 1536, "mlp_ratio": 2.66667*2,
    "num_classes": 0, "no_embed_class": True,
    "mlp_layer": timm.layers.SwiGLUPacked, "act_layer": torch.nn.SiLU,
    "reg_tokens": 8, "dynamic_img_size": True,
}
uni2_model = timm.create_model("hf-hub:MahmoodLab/UNI2-h", pretrained=True, **timm_kwargs).to(device)
uni2_model.eval()
uni2_cfg = resolve_data_config({}, model=uni2_model)
uni2_transform = create_transform(**uni2_cfg)


@torch.inference_mode()
def image_embedding_uni2(pil_img: Image.Image):
    img_t = uni2_transform(pil_img).unsqueeze(0).to(device, non_blocking=True)
    with torch.no_grad():
        feats = uni2_model(img_t)  # (1, 1536)
    if isinstance(feats, (list, tuple)):
        feats = feats[0]
    if feats.dim() > 2:
        feats = feats.mean(dim=(2, 3))
    feats = torch.nn.functional.normalize(feats, dim=-1)
    return feats.squeeze(0).detach().cpu().tolist()

# =========================
# âœ… ì„ë² ë”©: GigaPath (timm í—ˆë¸Œ)
# =========================
giga_model = timm.create_model("hf_hub:prov-gigapath/prov-gigapath", pretrained=True).to(device)
giga_model.eval()
giga_transform = transforms.Compose([
    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225)),
])

@torch.inference_mode()
def image_embedding_gigapath(pil_img: Image.Image):
    x = giga_transform(pil_img).unsqueeze(0).to(device, non_blocking=True)
    feat = giga_model(x)
    if isinstance(feat, (list, tuple)):
        feat = feat[0]
    if feat.dim() > 2:
        feat = feat.mean(dim=(2, 3))
    feat = torch.nn.functional.normalize(feat, dim=-1)
    return feat.squeeze(0).cpu().tolist()

# =========================
# âœ… ë©”ì¸ ì‹¤í–‰
# =========================
def main():
    # --- DB/ì»¬ë ‰ì…˜ ì—°ê²° ---
    client_uni2 = PersistentClient(path=UNI2_DB_PATH, settings=Settings(allow_reset=False))
    client_giga = PersistentClient(path=GIGA_DB_PATH, settings=Settings(allow_reset=False))
    col_uni2 = client_uni2.get_or_create_collection(name=UNI2_COL_NAME)
    col_giga = client_giga.get_or_create_collection(name=GIGA_COL_NAME)

    # --- ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ ---
    slide_dirs = sorted(
        [os.path.join(ROOT_DIR, d) for d in os.listdir(ROOT_DIR) if os.path.isdir(os.path.join(ROOT_DIR, d))]
    )

    results = []
    use_fp16 = (device.type == "cuda")

    for slide_dir in slide_dirs:
        slide_id = os.path.basename(slide_dir)
        tile_paths = sorted([os.path.join(slide_dir, f) for f in os.listdir(slide_dir) if f.lower().endswith(".jpg")])

        if not tile_paths:
            print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
            continue

        vote_scores = defaultdict(float)

        for path in tile_paths:
            try:
                img = Image.open(path).convert("RGB")

                # 1) ê° DB ì „ìš© ì„ë² ë”©
                if use_fp16 and device.type == "cuda":
                    with torch.cuda.amp.autocast(dtype=torch.float16):
                        emb_uni2 = image_embedding_uni2(img)
                        emb_giga = image_embedding_gigapath(img)
                else:
                    emb_uni2 = image_embedding_uni2(img)
                    emb_giga = image_embedding_gigapath(img)

                # 2) ê° DBì—ì„œ í›„ë³´ ê²€ìƒ‰
                q_u = col_uni2.query(
                    query_embeddings=[emb_uni2],
                    n_results=K_BASE,
                    include=["metadatas", "distances"]
                )
                q_g = col_giga.query(
                    query_embeddings=[emb_giga],
                    n_results=K_BASE,
                    include=["metadatas", "distances"]
                )

                ids_u   = q_u.get("ids",[[]])[0]
                dists_u = q_u.get("distances",[[]])[0]
                metas_u = q_u.get("metadatas",[[]])[0]

                ids_g   = q_g.get("ids",[[]])[0]
                dists_g = q_g.get("distances",[[]])[0]
                metas_g = q_g.get("metadatas",[[]])[0]

                # 3) ê²°í•© ìŠ¤ì½”ì–´ ê³„ì‚°
                meta_map = {}
                for cid, m in zip(ids_u, metas_u):
                    meta_map[cid] = m
                for cid, m in zip(ids_g, metas_g):
                    if cid not in meta_map:
                        meta_map[cid] = m

                if FUSION_METHOD == "rrf":
                    fused = rrf_fuse(ids_u, ids_g, k=60)
                    merged = sorted(fused.items(), key=lambda x: x[1], reverse=True)[:FUSION_TOPK]
                else:
                    sim_u = to_similarity_from_distance(dists_u, metric=METRIC)
                    sim_g = to_similarity_from_distance(dists_g, metric=METRIC)
                    fused_scores = defaultdict(float)

                    if FUSION_METHOD == "zsum":
                        zn_u = z_norm(sim_u)
                        zn_g = z_norm(sim_g)
                        for cid, s in zip(ids_u, zn_u):
                            fused_scores[cid] += W_UNI2*float(s)
                        for cid, s in zip(ids_g, zn_g):
                            fused_scores[cid] += W_GIGA*float(s)

                    elif FUSION_METHOD == "softsum":
                        p_u = softmax(sim_u)
                        p_g = softmax(sim_g)
                        for cid, s in zip(ids_u, p_u):
                            fused_scores[cid] += W_UNI2*float(s)
                        for cid, s in zip(ids_g, p_g):
                            fused_scores[cid] += W_GIGA*float(s)

                    else:
                        raise ValueError("ì•Œ ìˆ˜ ì—†ëŠ” FUSION_METHOD")

                    merged = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)[:FUSION_TOPK]

                # 4) ìŠ¬ë¼ì´ë“œ ìº¡ì…˜ íˆ¬í‘œ
                for cid, fscore in merged:
                    meta = meta_map.get(cid, {}) or {}
                    caption = meta.get("caption", "(ì—†ìŒ)")
                    if VOTE_MODE == "weighted":
                        vote_scores[caption] += float(fscore)
                    else:
                        vote_scores[caption] += 1.0

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

        if not vote_scores:
            print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
            continue

        final_caption, final_score = max(vote_scores.items(), key=lambda x: x[1])
        print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} (ì ìˆ˜: {final_score:.2f}, vote={VOTE_MODE}, fusion={FUSION_METHOD}, K_base={K_BASE}, N={FUSION_TOPK})")
        print(f"ğŸ“„ {final_caption}")

        results.append({
            "id": f"{slide_id}.tiff",
            "report": final_caption
        })

    # 5) ì €ì¥
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
