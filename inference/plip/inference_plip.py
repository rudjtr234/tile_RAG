
\
import os
import json
from collections import defaultdict
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel
from chromadb import PersistentClient

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.3.0"
collection_name = "tile_embeddings_plip"

top_k = 3                     # â† ì—¬ê¸°ì„œ 3 ë˜ëŠ” 5 ë“±ìœ¼ë¡œ ì¡°ì ˆ (top-K ì´ì›ƒ)
# vote_mode = "majority"
vote_mode = "weighted"        # "majority" or "weighted"
output_path = "predictions_v0.3.4.json"

# =========================
# âœ… ëª¨ë¸, DB ì´ˆê¸°í™” (PLIP)
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CLIPModel.from_pretrained("vinid/plip").to(device)
processor = CLIPProcessor.from_pretrained("vinid/plip")

client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)

# =========================
# âœ… ìœ í‹¸: ì„ë² ë”© ì¶”ì¶œ
# =========================
@torch.inference_mode()
def image_embedding(pil_img):
    inputs = processor(images=pil_img, return_tensors="pt").to(device)
    feats = model.get_image_features(**inputs)
    feats = feats / feats.norm(dim=-1, keepdim=True)
    return feats.squeeze().cpu().tolist()  # list[float]

# =========================
# âœ… ìŠ¬ë¼ì´ë“œ ì „ì²´ ì²˜ë¦¬
# =========================
results = []
slide_dirs = sorted([
    os.path.join(root_dir, d)
    for d in os.listdir(root_dir)
    if os.path.isdir(os.path.join(root_dir, d))
])

for slide_dir in slide_dirs:
    slide_id = os.path.basename(slide_dir)
    tile_paths = sorted([
        os.path.join(slide_dir, f)
        for f in os.listdir(slide_dir)
        if f.lower().endswith(".jpg")
    ])

    if not tile_paths:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
        continue

    # íˆ¬í‘œ ì ìˆ˜ ëˆ„ì (ìŠ¬ë¼ì´ë“œ ë‹¨ìœ„)
    vote_scores = defaultdict(float)

    for path in tile_paths:
        try:
            img = Image.open(path).convert("RGB")
            emb = image_embedding(img)

            q = collection.query(
                query_embeddings=[emb],
                n_results=top_k,                    # â† ìƒìœ„ K
                include=["metadatas", "distances"]  # distances í¬í•¨ (weightedìš©)
            )

            metas = q.get("metadatas", [[]])[0]
            dists = q.get("distances", [[]])[0]

            # ì´ íƒ€ì¼ì˜ Kê°œ ì´ì›ƒ ëª¨ë‘ ë°˜ì˜
            for m, d in zip(metas, dists):
                caption = (m or {}).get("caption", "(ì—†ìŒ)")
                if vote_mode == "weighted":
                    # cosine distance ê°€ì • â†’ ìœ ì‚¬ë„ ê·¼ì‚¬ì¹˜ë¡œ (1 - d) ì‚¬ìš©, ìŒìˆ˜ ë°©ì§€
                    w = max(0.0, 1.0 - float(d))
                    vote_scores[caption] += w
                else:
                    # majority: ë™ì¼ ê°€ì¤‘ì¹˜ 1
                    vote_scores[caption] += 1.0

        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

    if not vote_scores:
        print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
        continue

    # ìµœì¢… ìº¡ì…˜ ì„ íƒ
    final_caption = max(vote_scores.items(), key=lambda x: x[1])[0]
    final_score = vote_scores[final_caption]

    print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} (ì ìˆ˜: {final_score:.2f}, mode={vote_mode}, K={top_k})")
    print(f"ğŸ“„ {final_caption}")

    results.append({
        "id": f"{slide_id}.tiff",
        "report": final_caption
    })

# =========================
# âœ… JSON ì €ì¥
# =========================
with open(output_path, "w", encoding="utf-8") as f:
    json.dump(results, f, ensure_ascii=False, indent=2)

print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")

