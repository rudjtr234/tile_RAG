import os
import json
from collections import defaultdict
from typing import List, Dict, Any

from PIL import Image
import torch
import numpy as np
from transformers import CLIPProcessor, CLIPModel
from chromadb import PersistentClient


# =========================
# âœ… ê¸°ë³¸ ì„¤ì • (í•„ìš” ì‹œ ìˆ˜ì •)
# =========================
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/test_set_v0.1.0"
db_path = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.3.0"
collection_name = "tile_embeddings_plip"

top_k = 3                        # ìƒìœ„ K ì´ì›ƒ
vote_mode = "weighted"           # "weighted" or "majority"
output_path = "predictions_v0.3.5.json"

# ğŸ”§ íŠœë‹ íŒŒë¼ë¯¸í„°
SIM_THRESHOLD = 0.28             # ìœ ì‚¬ë„ Ï„ (0~1). ë‚®ì€ í›„ë³´ ì»·. Noneì´ë©´ ë¹„í™œì„±
USE_SOFTMAX   = True             # weightedì—ì„œ softmax ê°€ì¤‘ì¹˜ ì‚¬ìš©
SOFTMAX_T     = 0.1              # softmax ì˜¨ë„(T). ì‘ì„ìˆ˜ë¡ ìƒìœ„ í›„ë³´ ì§‘ì¤‘
LOG_CONFIDENCE = True            # ìŠ¬ë¼ì´ë“œë³„ confidence ë¡œê¹…


# =========================
# âœ… ëª¨ë¸, DB ì´ˆê¸°í™” (PLIP)
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CLIPModel.from_pretrained("vinid/plip").to(device)
processor = CLIPProcessor.from_pretrained("vinid/plip")

client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)


# =========================
# âœ… ìœ í‹¸: ì†Œí”„íŠ¸ë§¥ìŠ¤ ê°€ì¤‘ì¹˜
# =========================
def softmax_w(scores: List[float], T: float = 0.1) -> List[float]:
    x = np.array(scores, dtype=np.float32) / max(T, 1e-6)
    x -= x.max()
    w = np.exp(x)
    w_sum = w.sum()
    return (w / (w_sum + 1e-9)).tolist()


# =========================
# âœ… ìœ í‹¸: ì´ë¯¸ì§€ ì„ë² ë”©
# =========================
@torch.inference_mode()
def image_embedding(pil_img: Image.Image) -> List[float]:
    inputs = processor(images=pil_img, return_tensors="pt").to(device)
    feats = model.get_image_features(**inputs)
    feats = feats / feats.norm(dim=-1, keepdim=True)  # L2 normalize
    return feats.squeeze().detach().cpu().tolist()


# =========================
# âœ… ìŠ¬ë¼ì´ë“œ ì „ì²´ ì²˜ë¦¬
# =========================
def main() -> None:
    # ìŠ¬ë¼ì´ë“œ ë””ë ‰í† ë¦¬ ìˆ˜ì§‘
    slide_dirs = sorted([
        os.path.join(root_dir, d)
        for d in os.listdir(root_dir)
        if os.path.isdir(os.path.join(root_dir, d))
    ])

    results: List[Dict[str, Any]] = []

    for slide_dir in slide_dirs:
        slide_id = os.path.basename(slide_dir)
        tile_paths = sorted([
            os.path.join(slide_dir, f)
            for f in os.listdir(slide_dir)
            if f.lower().endswith(".jpg")
        ])

        if not tile_paths:
            print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {slide_id} â†’ ìŠ¤í‚µ")
            continue

        vote_scores = defaultdict(float)   # ìº¡ì…˜ë³„ ê°€ì¤‘ì¹˜ í•©
        slide_confidence = 0.0            # ìŠ¬ë¼ì´ë“œ ì‹ ë¢°ë„(ì´ ê°€ì¤‘ì¹˜ í•©)

        for path in tile_paths:
            try:
                img = Image.open(path).convert("RGB")
                emb = image_embedding(img)

                q = collection.query(
                    query_embeddings=[emb],
                    n_results=top_k,
                    include=["metadatas", "distances"]
                )

                metas = q.get("metadatas", [[]])[0]
                dists = q.get("distances", [[]])[0]
                if not metas or not dists:
                    continue

                # distance â†’ cosine similarity
                sims: List[float] = []
                items: List[Dict[str, Any]] = []
                for m, d in zip(metas, dists):
                    try:
                        sim = max(0.0, 1.0 - float(d))  # cosine sim (ê°€ì •: distance=1-cos)
                    except Exception:
                        continue
                    if SIM_THRESHOLD is not None and sim < SIM_THRESHOLD:
                        continue
                    items.append(m or {})
                    sims.append(sim)

                if not items:
                    continue

                # ê°€ì¤‘ì¹˜ ê³„ì‚°
                if vote_mode == "weighted":
                    if USE_SOFTMAX:
                        ws = softmax_w(sims, T=SOFTMAX_T)
                    else:
                        ws = sims  # similarity ê·¸ëŒ€ë¡œ ê°€ì¤‘ì¹˜ë¡œ ì‚¬ìš©
                else:
                    ws = [1.0] * len(items)  # majority

                # ìº¡ì…˜ë³„ ì ìˆ˜ ëˆ„ì 
                for m, w in zip(items, ws):
                    caption = m.get("caption", "(ì—†ìŒ)")
                    vote_scores[caption] += float(w)
                    slide_confidence += float(w)

            except Exception as e:
                print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

        if not vote_scores:
            print(f"âš ï¸ ìº¡ì…˜ ì—†ìŒ: {slide_id}")
            continue

        final_caption, final_score = max(vote_scores.items(), key=lambda x: x[1])

        # ë¡œê·¸ ì¶œë ¥
        print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸: {slide_id} "
              f"(score={final_score:.3f}, conf={slide_confidence:.3f}, "
              f"mode={vote_mode}, K={top_k}, tau={SIM_THRESHOLD}, T={SOFTMAX_T if USE_SOFTMAX else None})")
        print(f"ğŸ“„ {final_caption}")

        # ê²°ê³¼ ì €ì¥ ì˜¤ë¸Œì íŠ¸
        obj = {
            "id": f"{slide_id}.tiff",
            "report": final_caption
        }
        if LOG_CONFIDENCE:
            obj.update({
                "confidence": round(slide_confidence, 3),
                "topk": top_k,
                "mode": vote_mode,
                "tau": SIM_THRESHOLD,
                "softmax_T": SOFTMAX_T if USE_SOFTMAX else None
            })
        results.append(obj)

    # JSON ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ“ ì „ì²´ ê²°ê³¼ JSON ì €ì¥ ì™„ë£Œ: {output_path}")


if __name__ == "__main__":
    main()
