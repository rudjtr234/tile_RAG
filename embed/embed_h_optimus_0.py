import os
import json
from PIL import Image
import torch
import numpy as np
from tqdm import tqdm
from chromadb import PersistentClient

import timm
from torchvision import transforms
from timm.data import resolve_data_config
from timm.data.transforms_factory import create_transform

# ======================
# âœ… ë””ë°”ì´ìŠ¤
# ======================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ======================
# âœ… H-optimus-0 ë¡œë“œ
#    - 224x224 ì…ë ¥ ê¶Œì¥
#    - ì§€ì • mean/std ì‚¬ìš©
#    - ì¶œë ¥: (1, 1536)
# ======================
model = timm.create_model(
    "hf-hub:bioptimus/H-optimus-0",
    pretrained=True,
    init_values=1e-5,
    dynamic_img_size=False,   # ê¶Œì¥: False
).to(device)
model.eval()

# ê¶Œì¥ ì „ì²˜ë¦¬ (H-optimus-0 ëª¨ë¸ ì¹´ë“œ ê¸°ì¤€)
# íƒ€ì¼ì´ 224ê°€ ì•„ë‹ˆë¼ë©´ Resizeë¥¼ í†µí•´ 224ë¡œ ë§ì¶¥ë‹ˆë‹¤.
hopt_transform = transforms.Compose([
    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=(0.707223, 0.578729, 0.703617),
        std=(0.211883, 0.230117, 0.177517),
    ),
])

# ======================
# âœ… ChromaDB ì„¤ì •
# ======================
chroma_client = PersistentClient(
    path="/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.5.0"
)
collection = chroma_client.get_or_create_collection(name="tile_embeddings_HOPT0")

# ======================
# âœ… Groundtruth JSON ë¶ˆëŸ¬ì˜¤ê¸°
# ======================
with open("/home/mts/ssd_16tb/member/jks/reg2025_tile_RAG/embed/ground_truth_all.json", "r") as f:
    groundtruth = json.load(f)

# âœ… ìŠ¬ë¼ì´ë“œ ID â†’ ìº¡ì…˜ ë§µ
slide_to_caption = {
    item["id"].replace(".tiff", ""): item["report"] for item in groundtruth
}

# âœ… ê³µí†µëœ ìŠ¬ë¼ì´ë“œ IDë§Œ ì¶”ì¶œ
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/train_set_v0.1.0"
gt_slide_ids = set(slide_to_caption.keys())
tile_slide_ids = set([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])
matched_ids = sorted(list(gt_slide_ids & tile_slide_ids))

# ======================
# âœ… ì„ë² ë”© í•¨ìˆ˜ (H-optimus-0)
#   - ì¶œë ¥: (1536,) numpy
#   - L2 ì •ê·œí™”
# ======================
@torch.inference_mode()
def get_embedding(img_path: str) -> np.ndarray:
    image = Image.open(img_path).convert("RGB")
    tensor = hopt_transform(image).unsqueeze(0).to(device)  # [1, 3, 224, 224]
    use_amp = (device.type == "cuda")
    if use_amp:
        with torch.autocast(device_type="cuda", dtype=torch.float16):
            feat = model(tensor)  # [1, 1536]
    else:
        feat = model(tensor)
    feat = torch.nn.functional.normalize(feat, dim=-1)  # L2 ì •ê·œí™”
    return feat.squeeze(0).detach().cpu().numpy()       # (1536,)

# ======================
# âœ… íƒ€ì¼ ë””ë ‰í† ë¦¬ ë‹¨ìœ„ ì €ì¥ í•¨ìˆ˜
# ======================
def embed_and_store(img_dir: str, slide_id: str, caption: str):
    files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith((".jpg", ".jpeg", ".png"))])
    if not files:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {img_dir}")
        return

    embeddings, ids, metadatas = [], [], []

    for fname in tqdm(files, desc=f"Embedding {slide_id}"):
        img_path = os.path.join(img_dir, fname)
        emb = get_embedding(img_path)  # (1536,)
        embeddings.append(emb.tolist())
        tile_id = f"{slide_id}_{fname}"
        ids.append(tile_id)
        metadatas.append({
            "slide_id": slide_id,
            "tile_name": fname,
            "tile_path": img_path,
            "caption": caption
        })

    # ğŸ” ë°°ì¹˜ ì¶”ê°€ ì‹œ ChromaDBê°€ ë„ˆë¬´ ì»¤ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ë ¤ë©´ chunking ê³ ë ¤
    collection.add(embeddings=embeddings, ids=ids, metadatas=metadatas)

# ======================
# âœ… ë©”ì¸ ë£¨í”„
# ======================
if __name__ == "__main__":
    for slide_id in matched_ids:
        slide_dir = os.path.join(root_dir, slide_id)
        try:
            # ğŸ”¥ ê¸°ì¡´ slide_id ë°ì´í„° ì‚­ì œ í›„ ì¬ì‚½ì…
            collection.delete(where={"slide_id": slide_id})
            embed_and_store(slide_dir, slide_id, slide_to_caption[slide_id])
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {slide_id}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {slide_id} â†’ {e}")
