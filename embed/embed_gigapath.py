import os
import json
from PIL import Image
import torch
import numpy as np
from tqdm import tqdm
from chromadb import PersistentClient

# ğŸ” ì¶”ê°€: gigapath íƒ€ì¼ ì¸ì½”ë” ë¡œë”©ì„ ìœ„í•œ timm/torchvision
import timm
from torchvision import transforms

# =========================
# âœ… ê¸°ë³¸ ì„¤ì •
# =========================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# =========================
# âœ… GigaPath íƒ€ì¼ ì¸ì½”ë” ë¡œë”©
#    - ì‚¬ì „ì— HF ë™ì˜ & í† í° í•„ìš”:
#      export HF_TOKEN=xxxxx
# =========================
# ì°¸ê³ : https://huggingface.co/prov-gigapath/prov-gigapath (Model card)
tile_encoder = timm.create_model("hf_hub:prov-gigapath/prov-gigapath", pretrained=True).to(device)
tile_encoder.eval()

# GigaPath ê¶Œì¥ ì „ì²˜ë¦¬ (HF Model Card ì˜ˆì‹œì™€ ë™ì¼)
transform = transforms.Compose([
    transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.485, 0.456, 0.406),
                         std=(0.229, 0.224, 0.225)),
])

# =========================
# âœ… ChromaDB ì„¤ì •
# =========================
chroma_client = PersistentClient(
    path="/home/mts/ssd_16tb/member/jks/tile_RAG_data/vectorDB/tile_RAG_embedding_db_v0.6.0"
)
collection = chroma_client.get_or_create_collection(name="tile_embeddings_gigapath")

# =========================
# âœ… Groundtruth JSON ë¶ˆëŸ¬ì˜¤ê¸°
# =========================
with open("/home/mts/ssd_16tb/member/jks/reg2025_tile_RAG/embed/ground_truth_all.json", "r") as f:
    groundtruth = json.load(f)

# âœ… ìŠ¬ë¼ì´ë“œ ID â†’ ìº¡ì…˜ ë§µ
slide_to_caption = {
    item["id"].replace(".tiff", ""): item["report"] for item in groundtruth
}

# âœ… ê³µí†µëœ ìŠ¬ë¼ì´ë“œ IDë§Œ ì¶”ì¶œ
root_dir = "/home/mts/ssd_16tb/member/jks/tile_RAG_data/train_set_v0.1.0"
gt_slide_ids = set(slide_to_caption.keys())
tile_slide_ids = set([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])
matched_ids = sorted(list(gt_slide_ids & tile_slide_ids))

# =========================
# âœ… ì„ë² ë”© í•¨ìˆ˜ (GigaPath)
#   - ì¶œë ¥: 1536-d ë²¡í„° (L2 ì •ê·œí™”)
# =========================
@torch.inference_mode()
def get_embedding(img_path):
    img = Image.open(img_path).convert("RGB")
    x = transform(img).unsqueeze(0).to(device, non_blocking=True)
    feat = tile_encoder(x)                 # [1, 1536]
    feat = torch.nn.functional.normalize(feat, dim=-1)  # L2 norm
    return feat.squeeze(0).cpu().numpy()

# =========================
# âœ… íƒ€ì¼ ë””ë ‰í† ë¦¬ ë‹¨ìœ„ ì €ì¥ í•¨ìˆ˜
# =========================
def embed_and_store(img_dir, slide_id, caption):
    files = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(".jpg")])
    if not files:
        print(f"âš ï¸ íƒ€ì¼ ì—†ìŒ: {img_dir}")
        return

    embeddings, ids, metadatas = [], [], []

    for fname in tqdm(files, desc=f"Embedding {slide_id} (GigaPath)"):
        img_path = os.path.join(img_dir, fname)
        emb = get_embedding(img_path)
        embeddings.append(emb.tolist())
        tile_id = f"{slide_id}_{fname}"
        ids.append(tile_id)
        metadatas.append({
            "slide_id": slide_id,
            "tile_name": fname,
            "tile_path": img_path,
            "caption": caption
        })

    collection.add(embeddings=embeddings, ids=ids, metadatas=metadatas)

# =========================
# âœ… ë©”ì¸ ë£¨í”„
# =========================
if __name__ == "__main__":
    for slide_id in matched_ids:
        slide_dir = os.path.join(root_dir, slide_id)
        try:
            # ê¸°ì¡´ slide_id ë°ì´í„° ì‚­ì œ í›„ ì¬ì‚½ì…
            collection.delete(where={"slide_id": slide_id})
            embed_and_store(slide_dir, slide_id, slide_to_caption[slide_id])
            print(f"âœ… ì €ì¥ ì™„ë£Œ (GigaPath): {slide_id}")
        except Exception as e:
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {slide_id} â†’ {e}")
