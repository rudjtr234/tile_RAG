import os
from collections import Counter
from PIL import Image
import torch
from transformers import CLIPProcessor, CLIPModel
from chromadb import PersistentClient

# âœ… ì„¤ì •
img_dir = "/home/mts/ssd_16tb/member/jks/medgemma_reg2025/notebooks/data/REG_2025_tile_preprocess_final_v.0.2.1/PIT_01_00333_01"
db_path = "/home/mts/ssd_16tb/member/jks/reg2025_tile_RAG/chroma_db"
collection_name = "tile_embeddings"
top_k = 1  # íƒ€ì¼ë§ˆë‹¤ ê°€ì¥ ìœ ì‚¬í•œ ê²ƒë§Œ

# âœ… ëª¨ë¸ & DB
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = CLIPModel.from_pretrained("openai/clip-vit-base-patch16").to(device)
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch16")
client = PersistentClient(path=db_path)
collection = client.get_or_create_collection(name=collection_name)

# âœ… íƒ€ì¼ ì´ë¯¸ì§€ ê²½ë¡œ ìˆ˜ì§‘
tile_paths = sorted([os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.endswith(".jpg")])

# âœ… ê²°ê³¼ ì €ì¥
captions = []
all_results = []

for path in tile_paths:
    try:
        image = Image.open(path).convert("RGB")
        inputs = processor(images=image, return_tensors="pt").to(device)
        with torch.no_grad():
            image_features = model.get_image_features(**inputs)
            image_features = image_features / image_features.norm(dim=-1, keepdim=True)
        embedding = image_features.squeeze().cpu().tolist()

        # ğŸ” DB ê²€ìƒ‰
        results = collection.query(
            query_embeddings=[embedding],
            n_results=top_k,
            include=["metadatas", "documents", "distances"]
        )
        
        metadata = results["metadatas"][0][0]
        caption = metadata.get("caption", "(ì—†ìŒ)")
        distance = results["distances"][0][0]
        tile_name = os.path.basename(path)

        captions.append(caption)
        all_results.append((tile_name, caption, distance))

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {path} â†’ {e}")

# âœ… Caption í†µê³„
caption_counts = Counter(captions)
most_common_caption, count = caption_counts.most_common(1)[0]

# âœ… ìµœì¢… ê²°ê³¼ ì¶œë ¥
print(f"\nâœ… ìµœì¢… ë³‘ë¦¬ ë¦¬í¬íŠ¸ (ë¹ˆë„ìˆ˜ ê¸°ì¤€: {count}íšŒ)\nğŸ“„ {most_common_caption}")

